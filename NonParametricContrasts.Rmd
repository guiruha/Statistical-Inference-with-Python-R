---
title: "NonParametricContrasts"
author: "Guillem"
date: "18 February 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Contrastes no parámetricos de forma visual
#### Histogramas

```{r}
muestra = iris$Sepal.Width
plot(density(muestra), main = "Estimación de la densidad")
```
Como podemos observar en el gráfico de densidad, la distribución presenta bastantes indicios de ser una normal.

```{r}
muestra = iris$Sepal.Width
plot(density(muestra), main = "Estimación de la densidad")
x = seq(from=1, to = 5, by =  0.01)
mu = mean(iris$Sepal.Width)
sigma = sd(iris$Sepal.Width)
lines(x, dnorm(x,mean=mu,sd=sigma), col = "red")
```
Vemos que la campana de Gauss se parece bastante a la estimación de la densidad.
La cuestión ahora es: ¿podemos aceptar que el parecido es suficiente para aceptar que la distribución de la anchura del sépalo es normal?

#### QQ-plot

```{r}

qqnorm(y = iris$Sepal.Width)
qqline(y = iris$Sepal.Width, distribution = qnorm)
qqline(y = iris$Sepal.Width + 0.50/2, distribution = qnorm)

```


# Contraste $\chi²$ de Pearson

```{r}
set.seed(2020)
muestra_flores <- sample(iris$Species, 10)
flores_escogidas <- iris[muestra_flores,]
table(muestra_flores)

chisq.test(table(muestra_flores))
```
R nos avisa que las aproximaciones pueden ser incorrectas. La razón es que las **frecuencias observadas** no son mayores que 5 ya que éstas valen $e_{setosa}=e_{virginica}=e_{versicolor} = \frac{10}{3} \approx  3.3333$

Para solventar este problema, vamos a simular el p-valor:

```{r}
chisq.test(table(muestra_flores), simulate.p.value = TRUE, B = 2000)
```
Con 2000 replicaciones, al obtener un p-valor grande, no tenemos suficientes evidencias para rechazar que la proporción de especies en la muestra no sea la misma

```{r}
extremos_izquierdos <- c(-Inf, 1.95, 2.45, 2.95, 3.45, 3.95, 4.45)
extremos_derechos <- c(1.95, 2.45, 2.95, 3.45, 3.95, 4.45, Inf)
frecuencias_empiricas <- c(2, 1,4, 15, 10, 5, 3)
n = sum(frecuencias_empiricas)
```

```{r}
mu = 3.5; sigma = 0.7;
probabilidades_teoricas <- pnorm(extremos_derechos, mu, sigma) - pnorm(extremos_izquierdos, mu, sigma)

chisq.test(frecuencias_empiricas, p = probabilidades_teoricas)

chisq.test(frecuencias_empiricas, p = probabilidades_teoricas, simulate.p.value = TRUE, B = 2000)
```

# Contraste $\chi^2$ de Pearson con parámetros desconocidos

```{r}
frecuencias_empiricas <- c(229, 211, 93, 35, 8)
estimacion_lambda <- (211+93*2+35*3+7*4+1*5)/(229+211+93+35+7+1)
probabilidades_esperadas <- c(dpois(0, estimacion_lambda), dpois(1, estimacion_lambda), dpois(2, estimacion_lambda), dpois(3, estimacion_lambda), 1-ppois(3, estimacion_lambda))

chisq.test(frecuencias_empiricas, p=probabilidades_esperadas)
```
Aunque este contraste podría ser fiable, no está teniendo en cuenta que estamos estimando un parámetro, por lo que se debería restar 1 a los grados de libertad. Como solución podemos hacer:

```{r}
test.chi2 = chisq.test(frecuencias_empiricas, p = probabilidades_esperadas)

pchisq(test.chi2[[1]],3, lower.tail = FALSE)
```

# Test Kolmogorov-Sminorv

Se cree que el tiempo en segundos entre dos reservas de vuelo en un portal web en un mismo día podría ser una distribución exponencial con parámetro $\lambda = 1/5$. Una muestra de 10 tiempos entre reservas consecutivas de vuelos medidos en segundos es la siguiente:

```{r}
ks.test(muestra_coches, "ppois", 3.7)
```

```{r}
x = c(1.6, 1.8, 2.8, 5.9, 4.3, 4.7, 4.8, 7.3, 8.7, 11.1)
```

* ¿Cuál es la distribución teórica propuesta?

$$
F_X(x) = \left\{
\begin{array}{ll}
1 - e^{-\frac{x}{5}} & \textrm{si}\ x>0 \\
0 & \textrm{en otro caso}
\end{array}
\right .
$$
$$
\left\{
\begin{array}{ll}
H_0: & \textrm{Los datos provienen de una distribución } Exp(\frac{1}{5}) \\
H_1 : & \textrm{Los datos NO provienen de tal distribución}
\end{array}
\right.
$$
* Contrastamos la $H_0$ con un test KS al nivel de significación $\alpha = 0.1$

$$
D_{10} = \max_{1\leq i \leq 10} \left(\max\{|F_X(x_i) - \frac{i-1}{10}|, |F_X(x_i) - \frac{i}{10}|\}\right)$$

```{r}
i = 1:10
Fx = 1-exp(-x/5)

df = data.frame(i = i, xi = x,
                Fx = Fx,
                Fx1 = abs(Fx - (i-1)/10),
                Fx2 = abs(Fx - i/10))
df$FxM = pmax(df$Fx1, df$Fx2)

knitr::kable(df)



D = max(df$FxM)
D

ks.test(x, "pexp", 1/5)
```
Como el $p_{value} = 0.3595 > 0.05$ tenemos evidencias suficientes para no rechazar $H_0$

# Test Kolmogorov-Smirnov-Lilliefors

```{r}
library(nortest)
lillie.test(x)
```

Uno de los inconvenientes de lilliefors test es que le cuesta detectar diferencias prominentes en un extremo u otro de la distribución, comprobemos este problema con una $t de Student$

```{r}
set.seed(100)
x = rt(50, 3)
lillie.test(x)
```
Como observamos nos da un $p_{value} = 0.205$ por lo que no podemos rechazar que se distribuya en una normal, esto es debido a que la función de densidad de la t de Student es algo más aplanada a la norma y el test K-S-L test no es capaz de detectar las diferencias sutiles en los extremos de las colas

# Test Anderson-Darling

```{r}
set.seed(100)
x = rt(50, 3)
ad.test(x)
```

# Test Shapiro-Wilks

```{r}
set.seed(100)
x = rt(50, 3)
shapiro.test(x)
```

# Test omnibuys de D'Agostino-Pearson

```{r}
set.seed(100)
x = rt(50, 3)
library(fBasics)
dagoTest(x)
```